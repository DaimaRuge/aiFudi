# PyTorch ExecuTorch é¡¹ç›®æ·±åº¦åˆ†ææŠ¥å‘Š

**åˆ†ææ—¶é—´**: 2026-02-22
**é¡¹ç›®åœ°å€**: https://github.com/pytorch/executorch
**åˆ†æç›®æ ‡**: ä¸ºåŸºäº OpenClaw çš„æ™ºèƒ½å®¶å±…æ¡†æ¶æä¾›è¾¹ç¼˜ AI æ¨ç†è§£å†³æ–¹æ¡ˆ

---

## ç›®å½•

- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. ä»£ç æ¶æ„](#2-ä»£ç æ¶æ„)
- [3. é¡¹ç›®æ¨¡å—](#3-é¡¹ç›®æ¨¡å—)
- [4. é¡¹ç›®æ–‡ä»¶ç›®å½•ç»“æ„](#4-é¡¹ç›®æ–‡ä»¶ç›®å½•ç»“æ„)
- [5. æ ¸å¿ƒæŠ€æœ¯](#5-æ ¸å¿ƒæŠ€æœ¯)
- [6. æ ¸å¿ƒæ–‡ä»¶](#6-æ ¸å¿ƒæ–‡ä»¶)
- [7. éƒ¨ç½²åˆ° OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶](#7-éƒ¨ç½²åˆ°-openclaw-æ™ºèƒ½å®¶å±…æ¡†æ¶)
- [8. æ€»ç»“ä¸å»ºè®®](#8-æ€»ç»“ä¸å»ºè®®)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½

**ExecuTorch** æ˜¯ PyTorch å®˜æ–¹çš„ç«¯ä¾§ AI ç»Ÿä¸€éƒ¨ç½²è§£å†³æ–¹æ¡ˆï¼Œä¸“æ³¨äºåœ¨ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ç³»ç»Ÿå’Œè¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œ AI æ¨¡å‹ã€‚

**æ ¸å¿ƒä»·å€¼**:
- ğŸ”’ **éšç§ä¿æŠ¤**: æ•°æ®æ— éœ€ç¦»å¼€è®¾å¤‡
- âš¡ **é«˜æ€§èƒ½**: ç»è¿‡ Meta æ——ä¸‹æ•°åäº¿ç”¨æˆ·éªŒè¯çš„ç”Ÿäº§çº§æ–¹æ¡ˆ
- ğŸ’¾ **è½»é‡çº§**: è¿è¡Œæ—¶åŸºç¡€å ç”¨ä»… 50KB
- ğŸš€ **å¤šå¹³å°æ”¯æŒ**: 12+ ç¡¬ä»¶åç«¯ï¼Œä»æ™ºèƒ½æ‰‹æœºåˆ°å¾®æ§åˆ¶å™¨
- ğŸ¯ **ä¸€é”®åˆ‡æ¢**: åŒä¸€æ¨¡å‹ï¼Œä¸€å¤„å¯¼å‡ºï¼Œå¤šå¤„éƒ¨ç½²

### 1.2 ç”Ÿäº§åº”ç”¨æ¡ˆä¾‹

ExecuTorch å·²åœ¨ Meta äº§å“çº¿å¤§è§„æ¨¡éƒ¨ç½²ï¼š
- **Instagram** - å®æ—¶å›¾åƒå¤„ç†ä¸æ¨è
- **WhatsApp** - ç«¯ä¾§æ™ºèƒ½åŠŸèƒ½
- **Quest 3** - VR/AR ä½“éªŒ
- **Ray-Ban Meta æ™ºèƒ½çœ¼é•œ** - å¤šæ¨¡æ€äº¤äº’

### 1.3 æŠ€æœ¯ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| åŸç”Ÿ PyTorch å¯¼å‡º | æ— éœ€ ONNX/TFLite è½¬æ¢ï¼Œä¿æŒæ¨¡å‹è¯­ä¹‰ |
| AOT ç¼–è¯‘ | æå‰ç¼–è¯‘ï¼Œè¿è¡Œæ—¶é›¶å¼€é”€ |
| ç¡¬ä»¶åŠ é€Ÿ | æ”¯æŒ NPU/GPU/DSP å¤šç§åŠ é€Ÿå™¨ |
| é‡åŒ–æ”¯æŒ | 8-bitã€4-bitã€åŠ¨æ€é‡åŒ– |
| åŠ¨æ€å½¢çŠ¶ | æ”¯æŒæœ‰ç•ŒåŠ¨æ€è¾“å…¥å°ºå¯¸ |
| è‡ªå®šä¹‰ç®—å­ | æ‰©å±•é¢†åŸŸç‰¹å®šå†…æ ¸ |

---

## 2. ä»£ç æ¶æ„

### 2.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PyTorch Model Source                     â”‚
â”‚                    (nn.Module Eager Mode)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Export Phase (AOT)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  torch.export() â†’ EXIR (Export IR)                      â”‚ â”‚
â”‚  â”‚  - ATen Dialect (ATen nodes)                           â”‚ â”‚
â”‚  â”‚  - å¯é€‰: é‡åŒ– (QAT/PTQ)                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Core ATen Dialect                                      â”‚ â”‚
â”‚  â”‚  - åˆ†è§£ä¸ºåŸºç¡€ç®—å­é›†                                      â”‚ â”‚
â”‚  â”‚  - æ›´å°çš„ç®—å­é›†åˆ                                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Edge Compilation Phase                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Edge Dialect                                            â”‚ â”‚
â”‚  â”‚  - ATen + dtype/memory layout                           â”‚ â”‚
â”‚  â”‚  - æ ‡é‡è½¬å¼ é‡                                            â”‚ â”‚
â”‚  â”‚  - Selective Build æ”¯æŒ                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                                    â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚      â–¼                                      â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Backend    â”‚                    â”‚  Custom     â”‚         â”‚
â”‚  â”‚  Delegate   â”‚                    â”‚  Passes     â”‚         â”‚
â”‚  â”‚  (QNN/      â”‚                    â”‚  (Fusion/   â”‚         â”‚
â”‚  â”‚   CoreML/   â”‚                    â”‚   Memory)   â”‚         â”‚
â”‚  â”‚   XNNPACK)  â”‚                    â”‚             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Compile to ExecuTorch Program                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  - é™æ€æ‰§è¡Œå›¾                                           â”‚ â”‚
â”‚  â”‚  - Out-variant ç®—å­                                     â”‚ â”‚
â”‚  â”‚  - AOT å†…å­˜è§„åˆ’                                         â”‚ â”‚
â”‚  â”‚  - Flatbuffer åºåˆ—åŒ– (.pte æ–‡ä»¶)                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  On-Device Runtime                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  C++ è¿è¡Œæ—¶ (50KB åŸºç¡€å ç”¨)                             â”‚ â”‚
â”‚  â”‚  - Platform Abstraction Layer                          â”‚ â”‚
â”‚  â”‚  - Kernel/Backend Registry                             â”‚ â”‚
â”‚  â”‚  - Memory Management                                    â”‚ â”‚
â”‚  â”‚  - Execution Engine                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ä¸‰é˜¶æ®µå·¥ä½œæµ

#### Phase 1: ç¨‹åºå‡†å¤‡ (Program Preparation)

åœ¨æ¨¡å‹éƒ¨ç½²ä¹‹å‰å®Œæˆæ‰€æœ‰ç¹é‡å·¥ä½œï¼š

**æ­¥éª¤**:
1. **Export** - æ•è· PyTorch æ¨¡å‹å›¾
2. **Transform** - åˆ†è§£ç®—å­ã€åº”ç”¨é‡åŒ–
3. **Compile** - åˆ†åŒºåˆ°ç¡¬ä»¶åç«¯ã€ä¼˜åŒ–
4. **Serialize** - è¾“å‡º .pte æ–‡ä»¶

**ä¼˜åŠ¿**:
- è¿è¡Œæ—¶é›¶å¼€é”€
- é™æ€å†…å­˜åˆ†é…ï¼ˆæ— åŠ¨æ€ malloc/freeï¼‰
- æå‰å‘ç°é”™è¯¯

#### Phase 2: è¿è¡Œæ—¶å‡†å¤‡ (Runtime Preparation)

**Selective Build**:
- ä»…é“¾æ¥ç¨‹åºä½¿ç”¨çš„å†…æ ¸
- æ˜¾è‘—å‡å°‘äºŒè¿›åˆ¶å¤§å°
- åµŒå…¥å¼ç³»ç»Ÿå…³é”®

#### Phase 3: ç¨‹åºæ‰§è¡Œ (Program Execution)

**æ ¸å¿ƒè¿è¡Œæ—¶ç»„ä»¶**:
- å¹³å°æŠ½è±¡å±‚
- å†…æ ¸å’Œåç«¯æ³¨å†Œè¡¨
- å†…å­˜ç®¡ç†å™¨
- æ‰§è¡Œå¼•æ“

---

## 3. é¡¹ç›®æ¨¡å—

### 3.1 æ ¸å¿ƒæ¨¡å—åˆ’åˆ†

```
executorch/
â”œâ”€â”€ exir/                    # Export Intermediate Representation
â”‚   â”œâ”€â”€ dialect/             # å„ç§æ–¹è¨€ (ATen, Edge, Backend)
â”‚   â”œâ”€â”€ pass/                # ç¼–è¯‘ pass å’Œä¼˜åŒ–
â”‚   â””â”€â”€ to_executorch/       # è½¬æ¢ä¸º ExecuTorch æ ¼å¼
â”‚
â”œâ”€â”€ runtime/                 # C++ è¿è¡Œæ—¶
â”‚   â”œâ”€â”€ executor/            # æ‰§è¡Œå™¨æ ¸å¿ƒ
â”‚   â”œâ”€â”€ kernel/              # å†…æ ¸å®ç°
â”‚   â””â”€â”€ platform/            # å¹³å°æŠ½è±¡
â”‚
â”œâ”€â”€ backends/                # ç¡¬ä»¶åç«¯
â”‚   â”œâ”€â”€ xnnpack/             # XNNPACK CPU åç«¯
â”‚   â”œâ”€â”€ qualcomm/            # Qualcomm QNN åç«¯
â”‚   â”œâ”€â”€ coreml/              # Apple CoreML åç«¯
â”‚   â”œâ”€â”€ vulkan/              # Vulkan GPU åç«¯
â”‚   â””â”€â”€ arm/                 # ARM Ethos-U åç«¯
â”‚
â”œâ”€â”€ extension/               # æ‰©å±•åŠŸèƒ½
â”‚   â”œâ”€â”€ llm/                 # LLM æ”¯æŒå’Œè¿è¡Œå™¨
â”‚   â”œâ”€â”€ module/              # Python/C++ æ¨¡å—æ¥å£
â”‚   â””â”€â”€ tensor/              # å¼ é‡æ“ä½œ
â”‚
â”œâ”€â”€ schema/                  # Flatbuffer schema å®šä¹‰
â”‚   â””â”€â”€ program.fbs          # .pte æ–‡ä»¶æ ¼å¼å®šä¹‰
â”‚
â”œâ”€â”€ examples/                # ç¤ºä¾‹å’Œæ•™ç¨‹
â”‚   â”œâ”€â”€ models/              # æ¨¡å‹ç¤ºä¾‹ (Llama, Whisper ç­‰)
â”‚   â””â”€â”€ apps/                # åº”ç”¨ç¤ºä¾‹
â”‚
â””â”€â”€ sdk/                     # SDK å’Œå·¥å…·
    â”œâ”€â”€ cli/                 # å‘½ä»¤è¡Œå·¥å…·
    â””â”€â”€ etdump/              # æ€§èƒ½åˆ†æå·¥å…·
```

### 3.2 å„æ¨¡å—è¯¦è§£

#### 3.2.1 EXIR (Export Intermediate Representation)

**ä½œç”¨**: æ¨¡å‹å¯¼å‡ºå’Œè½¬æ¢çš„æ ¸å¿ƒ

**å…³é”®ç»„ä»¶**:
- **ATen Dialect**: PyTorch ATen ç®—å­å›¾è¡¨ç¤º
- **Core ATen Dialect**: åŸºç¡€ç®—å­é›†ï¼Œç”¨äºç¼–è¯‘
- **Edge Dialect**: ç«¯ä¾§ç‰¹å®šè¡¨ç¤ºï¼ˆå« dtype/layout ä¿¡æ¯ï¼‰

**è½¬æ¢æµç¨‹**:
```
PyTorch Model â†’ torch.export() â†’ EXIR (ATen) â†’ Core ATen â†’ Edge â†’ Backend
```

#### 3.2.2 Runtime (è¿è¡Œæ—¶)

**ç‰¹ç‚¹**:
- **æç®€è®¾è®¡**: ä»… 50KB åŸºç¡€å ç”¨
- **C++ å®ç°**: è·¨å¹³å°å…¼å®¹æ€§
- **æ¨¡å—åŒ–**: å†…æ ¸å¯é€‰æ‹©æ€§é“¾æ¥

**æ ¸å¿ƒç±»**:
- `Executor`: ä¸»æ‰§è¡Œå™¨
- `Method`: æ¨¡å‹æ–¹æ³•åŒ…è£…å™¨
- `EValue`: æ‰§è¡Œæ—¶å€¼è¡¨ç¤º
- `Tensor`: å¼ é‡æ•°æ®ç»“æ„

#### 3.2.3 Backends (ç¡¬ä»¶åç«¯)

**æ”¯æŒçš„ç¡¬ä»¶åç«¯**:

| åç«¯ | å¹³å° | åŠ é€Ÿå™¨ |
|------|------|--------|
| XNNPACK | Cross-platform | CPU (ARM/x86) |
| CoreML | iOS | Neural Engine |
| QNN | Android | Qualcomm NPU |
| Vulkan | Cross-platform | GPU |
| MPS | macOS | Metal Performance Shaders |
| Ethos-U | Embedded | ARM NPU |
| OpenVINO | Linux/Windows | Intel CPU/GPU/VPU |

**åç«¯é›†æˆæ–¹å¼**:
- **Delegate Pattern**: å­å›¾å§”æ‰˜åˆ°åç«¯
- **Partitioner**: è¯†åˆ«å¯å§”æ‰˜çš„å­å›¾
- **Fallback**: CPU ä½œä¸ºåå¤‡

#### 3.2.4 Extension LLM (å¤§è¯­è¨€æ¨¡å‹æ”¯æŒ)

**LLM ä¸“ç”¨åŠŸèƒ½**:
- **æ–‡æœ¬ç”Ÿæˆè¿è¡Œå™¨**: `TextLLMRunner`
- **å¤šæ¨¡æ€è¿è¡Œå™¨**: `MultiModalRunner` (vision, audio)
- **é‡åŒ–æ”¯æŒ**: 8-bit/4-bit LLM
- **ä¼˜åŒ–æŠ€æœ¯**: KV Cacheã€Speculative Decoding

**æ”¯æŒçš„æ¨¡å‹**:
- Llama 3.2/3.1/3
- Qwen 3
- Phi-4-mini
- Gemma 3
- Llava (vision-language)
- Voxtral (audio-language)

#### 3.2.5 Developer Tools (å¼€å‘å·¥å…·)

**å·¥å…·é›†**:
- **ETDump**: æ€§èƒ½åˆ†æå™¨
- **ETRecord**: æ‰§è¡Œè®°å½•æ£€æŸ¥å™¨
- **ETDebug**: æ¨¡å‹è°ƒè¯•å™¨
- **å¯è§†åŒ–å·¥å…·**: å›¾å¯è§†åŒ–ã€æ€§èƒ½çƒ­åŠ›å›¾

---

## 4. é¡¹ç›®æ–‡ä»¶ç›®å½•ç»“æ„

### 4.1 å®Œæ•´ç›®å½•æ ‘ï¼ˆæ¨æ–­ï¼‰

åŸºäºæ–‡æ¡£å’Œå¼€æºé¡¹ç›®æƒ¯ä¾‹ï¼ŒExecuTorch çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
executorch/
â”œâ”€â”€ .github/                     # GitHub é…ç½®
â”‚   â”œâ”€â”€ workflows/               # CI/CD å·¥ä½œæµ
â”‚   â””â”€â”€ ISSUE_TEMPLATE/          # Issue æ¨¡æ¿
â”‚
â”œâ”€â”€ backends/                    # ç¡¬ä»¶åç«¯å®ç°
â”‚   â”œâ”€â”€ xnnpack/
â”‚   â”‚   â”œâ”€â”€ partition/           # åˆ†åŒºå™¨å®ç°
â”‚   â”‚   â”œâ”€â”€ delegate/            # å§”æ‰˜åç«¯
â”‚   â”‚   â””â”€â”€ ops/                 # ç®—å­å®ç°
â”‚   â”œâ”€â”€ qualcomm/
â”‚   â”‚   â”œâ”€â”€ qnn/
â”‚   â”‚   â”‚   â”œâ”€â”€ delegate/
â”‚   â”‚   â”‚   â”œâ”€â”€ partitioner/
â”‚   â”‚   â”‚   â””â”€â”€ ops/
â”‚   â”‚   â””â”€â”€ htp/                 # Hexagon Tensor Processor
â”‚   â”œâ”€â”€ coreml/
â”‚   â”‚   â”œâ”€â”€ delegate/
â”‚   â”‚   â”œâ”€â”€ partitioner/
â”‚   â”‚   â””â”€â”€ ops/
â”‚   â”œâ”€â”€ vulkan/
â”‚   â”œâ”€â”€ arm/
â”‚   â”‚   â”œâ”€â”€ ethosu/              # ARM Ethos-U
â”‚   â”‚   â””â”€â”€ mali/                # ARM Mali GPU
â”‚   â””â”€â”€ cadence/                 # Cadence DSP
â”‚
â”œâ”€â”€ doc/                         # æ–‡æ¡£æºæ–‡ä»¶
â”‚   â”œâ”€â”€ source/
â”‚   â”‚   â”œâ”€â”€ _static/
â”‚   â”‚   â”œâ”€â”€ getting-started/
â”‚   â”‚   â”œâ”€â”€ tutorial/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â””â”€â”€ conf.py
â”‚
â”œâ”€â”€ exir/                        # Export IR
â”‚   â”œâ”€â”€ dialect/
â”‚   â”‚   â”œâ”€â”€ _ops.py              # ç®—å­å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ ops_schema.py
â”‚   â”‚   â””â”€â”€ graph_module.py
â”‚   â”œâ”€â”€ pass/
â”‚   â”‚   â”œâ”€â”€ memory_planning.py
â”‚   â”‚   â”œâ”€â”€ spec_pass.py         # Speculative decoding
â”‚   â”‚   â”œâ”€â”€ const_prop.py        # å¸¸é‡ä¼ æ’­
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ examples/                    # ç¤ºä¾‹å’Œæ•™ç¨‹
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ llama/               # Llama ç¤ºä¾‹
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ export_llm.py
â”‚   â”‚   â”‚   â””â”€â”€ quantize.py
â”‚   â”‚   â”œâ”€â”€ llava/               # Vision-Language æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ whisper/             # è¯­éŸ³è¯†åˆ«
â”‚   â”‚   â”œâ”€â”€ phi_4_mini/
â”‚   â”‚   â”œâ”€â”€ qwen3/
â”‚   â”‚   â””â”€â”€ gemma3/
â”‚   â””â”€â”€ apps/
â”‚       â”œâ”€â”€ ios/                 # iOS ç¤ºä¾‹åº”ç”¨
â”‚       â”œâ”€â”€ android/             # Android ç¤ºä¾‹åº”ç”¨
â”‚       â””â”€â”€ embedded/            # åµŒå…¥å¼ç¤ºä¾‹
â”‚
â”œâ”€â”€ extension/                   # æ‰©å±•æ¨¡å—
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ export/              # LLM å¯¼å‡ºå·¥å…·
â”‚   â”‚   â”œâ”€â”€ runner/              # LLM è¿è¡Œå™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ text_llm_runner.h
â”‚   â”‚   â”‚   â”œâ”€â”€ text_llm_runner.cpp
â”‚   â”‚   â”‚   â””â”€â”€ multmodal_runner.cpp
â”‚   â”‚   â”œâ”€â”€ training/           # LLM è®­ç»ƒæ”¯æŒ
â”‚   â”‚   â””â”€â”€ tools/               # LLM å·¥å…·
â”‚   â”œâ”€â”€ module/
â”‚   â”‚   â”œâ”€â”€ module.h
â”‚   â”‚   â”œâ”€â”€ module.cpp
â”‚   â”‚   â””â”€â”€ module.py
â”‚   â”œâ”€â”€ tensor/
â”‚   â”‚   â”œâ”€â”€ tensor.h
â”‚   â”‚   â”œâ”€â”€ tensor.cpp
â”‚   â”‚   â””â”€â”€ tensor.py
â”‚   â”œâ”€â”€ data_loader/             # æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ memory_allocator/        # å†…å­˜åˆ†é…å™¨
â”‚
â”œâ”€â”€ kernel/                      # å†…æ ¸å®ç°
â”‚   â”œâ”€â”€ portable/                # å¯ç§»æ¤å†…æ ¸ (CPU)
â”‚   â”‚   â”œâ”€â”€ optimized/           # ä¼˜åŒ–å†…æ ¸
â”‚   â”‚   â”œâ”€â”€ quantized/           # é‡åŒ–å†…æ ¸
â”‚   â”‚   â””â”€â”€ functions/
â”‚   â”œâ”€â”€ xnnpack/                 # XNNPACK å†…æ ¸åŒ…è£…
â”‚   â””â”€â”€ quantized/                # é‡åŒ–å†…æ ¸
â”‚
â”œâ”€â”€ runtime/                     # C++ è¿è¡Œæ—¶
â”‚   â”œâ”€â”€ executor/
â”‚   â”‚   â”œâ”€â”€ executor.h           # ä¸»æ‰§è¡Œå™¨
â”‚   â”‚   â”œâ”€â”€ executor.cpp
â”‚   â”‚   â”œâ”€â”€ method.h             # æ–¹æ³•åŒ…è£…
â”‚   â”‚   â”œâ”€â”€ program.h            # ç¨‹åºåŠ è½½
â”‚   â”‚   â””â”€â”€ evalue.h             # æ‰§è¡Œå€¼
â”‚   â”œâ”€â”€ platform/
â”‚   â”‚   â”œâ”€â”€ assert.h
â”‚   â”‚   â”œâ”€â”€ logger.h
â”‚   â”‚   â”œâ”€â”€ mutex.h
â”‚   â”‚   â””â”€â”€ platform.h
â”‚   â”œâ”€â”€ tensor/
â”‚   â”‚   â”œâ”€â”€ tensor.h
â”‚   â”‚   â””â”€â”€ tensor_impl.h
â”‚   â”œâ”€â”€ portable/                # å¯ç§»æ¤è¿è¡Œæ—¶
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ schema/                      # Flatbuffer Schema
â”‚   â”œâ”€â”€ program.fbs              # ç¨‹åºæ ¼å¼å®šä¹‰
â”‚   â”œâ”€â”€ flatbuffer_builder.h
â”‚   â””â”€â”€ flatbuffer_serializer.h
â”‚
â”œâ”€â”€ sdk/                         # SDK å’Œå·¥å…·
â”‚   â”œâ”€â”€ cli/                     # å‘½ä»¤è¡Œå·¥å…·
â”‚   â”‚   â”œâ”€â”€ export.py
â”‚   â”‚   â””â”€â”€ quantize.py
â”‚   â”œâ”€â”€ etdump/                  # æ€§èƒ½åˆ†æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ etdump.h
â”‚   â”‚   â”œâ”€â”€ etdump.cpp
â”‚   â”‚   â””â”€â”€ etdump_parser.py
â”‚   â”œâ”€â”€ etrecord/                # æ‰§è¡Œè®°å½•å·¥å…·
â”‚   â””â”€â”€ profiler/                # æ€§èƒ½åˆ†æå™¨
â”‚
â”œâ”€â”€ third_party/                 # ç¬¬ä¸‰æ–¹ä¾èµ–
â”‚   â”œâ”€â”€ xnnpack/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tools/                       # æ„å»ºå’Œæµ‹è¯•å·¥å…·
â”‚   â”œâ”€â”€ build_buck.py
â”‚   â”œâ”€â”€ cmake/
â”‚   â””â”€â”€ scripts/
â”‚
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE                      # BSD License
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ requirements.txt
```

### 4.2 å…³é”®ç›®å½•è¯´æ˜

#### 4.2.1 `backends/`

æ¯ä¸ªåç«¯åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼š
- **delegate/**: åç«¯å§”æ‰˜å®ç°
- **partitioner/**: å­å›¾åˆ†åŒºé€»è¾‘
- **ops/**: ç®—å­å®ç°

#### 4.2.2 `exir/`

ç¼–è¯‘å™¨æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š
- æ¨¡å‹å¯¼å‡º
- å›¾è½¬æ¢å’Œä¼˜åŒ–
- ç®—å­åˆ†è§£
- åç«¯åˆ†åŒº

#### 4.2.3 `runtime/`

è½»é‡çº§è¿è¡Œæ—¶ï¼Œç‰¹ç‚¹ï¼š
- å¤´æ–‡ä»¶é©±åŠ¨çš„ API
- æœ€å°ä¾èµ–ï¼ˆä»…æ ‡å‡†åº“ï¼‰
- å¹³å°æŠ½è±¡å±‚

#### 4.2.4 `extension/llm/`

LLM ä¸“ç”¨åŠŸèƒ½ï¼š
- å¯¼å‡ºè„šæœ¬
- æ–‡æœ¬/å¤šæ¨¡æ€è¿è¡Œå™¨
- KV Cache ä¼˜åŒ–
- é‡åŒ–å·¥å…·

---

## 5. æ ¸å¿ƒæŠ€æœ¯

### 5.1 AOT ç¼–è¯‘ (Ahead-of-Time Compilation)

**åŸç†**: åœ¨éƒ¨ç½²å‰å®Œæˆæ‰€æœ‰ç¼–è¯‘å’Œä¼˜åŒ–

**ä¼˜åŠ¿**:
- âœ… è¿è¡Œæ—¶é›¶ç¼–è¯‘å¼€é”€
- âœ… æå‰å‘ç°é”™è¯¯
- âœ… é™æ€å†…å­˜è§„åˆ’
- âœ… æ›´å¼ºçš„ä¼˜åŒ–ç©ºé—´

**æµç¨‹**:
```python
# 1. Export
exported_program = torch.export.export(model, example_inputs)

# 2. Transform & Lower
edge_program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[XnnpackPartitioner()]
)

# 3. Compile
executorch_program = edge_program.to_executorch()

# 4. Serialize
with open("model.pte", "wb") as f:
    f.write(executorch_program.buffer)
```

### 5.2 ç®—å­é›†æ ‡å‡†åŒ– (Core ATen Operator Set)

**ç›®æ ‡**: ç®€åŒ–ç®—å­é›†ï¼Œä¾¿äºç¼–è¯‘å™¨ä¼˜åŒ–

**ATen â†’ Core ATen è½¬æ¢**:
- **åˆ†è§£å¤æ‚ç®—å­**: å°† `aten::addmm` åˆ†è§£ä¸º `aten::matmul + aten::add`
- **ç»Ÿä¸€æ¥å£**: æ ‡å‡†åŒ–ç®—å­ç­¾å
- **å‡å°‘ä¾èµ–**: æ›´å°‘çš„ç®—å­å®ç°

**ç¤ºä¾‹**:
```
ATen:           aten::linear(input, weight, bias)
                â†“
Core ATen:      aten::matmul(input, weight.t())
                + aten::add(..., bias)
```

### 5.3 åç«¯å§”æ‰˜ (Backend Delegate)

**åŸç†**: å°†å­å›¾å§”æ‰˜åˆ°ä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿå™¨

**åˆ†åŒºæµç¨‹**:
1. **è¯†åˆ«å€™é€‰**: è¯†åˆ«å¯åŠ é€Ÿçš„ç®—å­æ¨¡å¼
2. **åˆ†åŒº**: å°†è¿ç»­çš„å¯åŠ é€Ÿç®—å­åˆ†ç»„
3. **å§”æ‰˜**: æ›¿æ¢ä¸ºåç«¯èŠ‚ç‚¹
4. **æ‰§è¡Œ**: è¿è¡Œæ—¶è°ƒç”¨åç«¯æ‰§è¡Œ

**ç¤ºä¾‹**:
```python
# Qualcomm QNN åˆ†åŒºå™¨
from executorch.backends.qualcomm.partition.qnn_partitioner import QnnPartitioner

program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[QnnPartitioner()]
)
```

### 5.4 å†…å­˜è§„åˆ’ (Memory Planning)

**é—®é¢˜**: åŠ¨æ€å†…å­˜åˆ†é…åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæœ‰é«˜æ˜‚å¼€é”€

**è§£å†³æ–¹æ¡ˆ**: AOT å†…å­˜è§„åˆ’

**ç­–ç•¥**:
1. **åˆ†æç”Ÿå‘½å‘¨æœŸ**: æ¯ä¸ªå¼ é‡çš„äº§ç”Ÿå’Œæ¶ˆäº¡
2. **é™æ€åˆ†é…**: é¢„å…ˆè®¡ç®—æ‰€éœ€å†…å­˜å¤§å°
3. **åŸåœ°å¤ç”¨**: å¤ç”¨å·²é‡Šæ”¾çš„å†…å­˜ç©ºé—´
4. **å†…å­˜æ± **: å‡å°‘ç¢ç‰‡åŒ–

**é…ç½®**:
```cpp
// è‡ªå®šä¹‰å†…å­˜è§„åˆ’å™¨
class CustomMemoryManager : public MemoryAllocator {
    // å®ç°è‡ªå®šä¹‰åˆ†é…ç­–ç•¥
};
```

### 5.5 é‡åŒ– (Quantization)

**æ”¯æŒçš„é‡åŒ–ç±»å‹**:
- **PTQ (Post-Training Quantization)**: è®­ç»ƒåé‡åŒ–
- **QAT (Quantization-Aware Training)**: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
- **åŠ¨æ€é‡åŒ–**: æŒ‰éœ€é‡åŒ–
- **é™æ€é‡åŒ–**: é¢„å…ˆé‡åŒ–

**ç²¾åº¦**:
- 8-bit (FP8, INT8)
- 4-bit (INT4, NF4)
- æ··åˆç²¾åº¦

**é›†æˆ**:
```python
from torchao.quantization import quantize

quantized_model = quantize(model, scheme="int8")
```

### 5.6 Selective Build (é€‰æ‹©æ€§æ„å»º)

**åŸç†**: ä»…é“¾æ¥ç¨‹åºä½¿ç”¨çš„ç®—å­

**æµç¨‹**:
1. åˆ†æ .pte æ–‡ä»¶ä¸­çš„ç®—å­é›†åˆ
2. ç”Ÿæˆç®—å­åˆ—è¡¨
3. é€‰æ‹©æ€§ç¼–è¯‘é“¾æ¥

**æ”¶ç›Š**:
- äºŒè¿›åˆ¶å¤§å°å‡å°‘ 60-80%
- æ›´å¿«çš„ç¼–è¯‘é€Ÿåº¦
- æ›´å°çš„å†…å­˜å ç”¨

### 5.7 Flatbuffer åºåˆ—åŒ–

**æ ¼å¼**: .pte (PyTorch ExecuTorch) æ–‡ä»¶

**ä¼˜åŠ¿**:
- âœ… è·¨å¹³å°å…¼å®¹
- âœ… é«˜æ•ˆåºåˆ—åŒ–/ååºåˆ—åŒ–
- âœ… å‰å‘å…¼å®¹æ€§
- âœ… ç´§å‡‘è¡¨ç¤º

**Schema**: `schema/program.fbs`

---

## 6. æ ¸å¿ƒæ–‡ä»¶

### 6.1 å¯¼å‡ºæµç¨‹æ ¸å¿ƒæ–‡ä»¶

#### Python ç«¯

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `exir/to_edge.py` | PyTorch â†’ Edge è½¬æ¢å…¥å£ |
| `exir/to_executorch.py` | Edge â†’ ExecuTorch è½¬æ¢ |
| `exir/dialect/graph_module.py` | å›¾æ¨¡å—è¡¨ç¤º |
| `exir/pass/memory_planning.py` | å†…å­˜è§„åˆ’ Pass |
| `exir/pass/spec_pass.py` | Speculative Decoding |

#### C++ ç«¯

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `runtime/executor/executor.h` | æ‰§è¡Œå™¨ä¸»ç±» |
| `runtime/executor/program.h` | ç¨‹åºåŠ è½½å™¨ |
| `runtime/executor/method.h` | æ–¹æ³•åŒ…è£…å™¨ |
| `runtime/executor/evalue.h` | æ‰§è¡Œæ—¶å€¼ |
| `schema/program.fbs` | .pte æ–‡ä»¶æ ¼å¼å®šä¹‰ |

### 6.2 è¿è¡Œæ—¶æ ¸å¿ƒæ–‡ä»¶

#### æ ¸å¿ƒè¿è¡Œæ—¶

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `runtime/platform/platform.h` | å¹³å°æŠ½è±¡å±‚ |
| `runtime/kernel/registry.h` | å†…æ ¸æ³¨å†Œè¡¨ |
| `runtime/executor/memory_allocator.h` | å†…å­˜åˆ†é…å™¨ |
| `runtime/extension/tensor/tensor.h` | å¼ é‡å®ç° |

#### LLM è¿è¡Œå™¨

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `extension/llm/runner/text_llm_runner.h` | æ–‡æœ¬ç”Ÿæˆè¿è¡Œå™¨ |
| `extension/llm/runner/multimodal_runner.h` | å¤šæ¨¡æ€è¿è¡Œå™¨ |
| `extension/llm/export/export_llm.py` | LLM å¯¼å‡ºå·¥å…· |
| `extension/llm/runner/llm_runner_types.h` | LLM ç±»å‹å®šä¹‰ |

### 6.3 åç«¯æ ¸å¿ƒæ–‡ä»¶

#### XNNPACK åç«¯

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `backends/xnnpack/partition/xnnpack_partitioner.py` | XNNPACK åˆ†åŒºå™¨ |
| `backends/xnnpack/delegate/xnnpack_delegate.h` | XNNPACK å§”æ‰˜ |
| `backends/xnnpack/ops/ops.cpp` | XNNPACK ç®—å­å®ç° |

#### Qualcomm åç«¯

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `backends/qualcomm/qnn/partitioner/qnn_partitioner.py` | QNN åˆ†åŒºå™¨ |
| `backends/qualcomm/qnn/delegate/qnn_delegate.h` | QNN å§”æ‰˜ |
| `backends/qualcomm/htp/delegate/htp_delegate.h` | HTP å§”æ‰˜ |

#### CoreML åç«¯

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `backends/coreml/partition/coreml_partitioner.py` | CoreML åˆ†åŒºå™¨ |
| `backends/coreml/delegate/coreml_delegate.h` | CoreML å§”æ‰˜ |

### 6.4 å¼€å‘å·¥å…·æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `sdk/etdump/etdump.h` | æ€§èƒ½åˆ†æå™¨ |
| `sdk/etdump/etdump_parser.py` | ETDump è§£æå™¨ |
| `sdk/etrecord/etrecord.h` | æ‰§è¡Œè®°å½•å·¥å…· |
| `examples/models/llama/export_llm.py` | Llama å¯¼å‡ºè„šæœ¬ |
| `examples/models/whisper/export_whisper.py` | Whisper å¯¼å‡ºè„šæœ¬ |

### 6.5 æ„å»ºé…ç½®æ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | ä½œç”¨ |
|----------|------|
| `setup.py` | Python åŒ…é…ç½® |
| `pyproject.toml` | ç°ä»£åŒ– Python é¡¹ç›®é…ç½® |
| `tools/cmake/` | CMake æ„å»ºè„šæœ¬ |
| `tools/build_buck.py` | Buck æ„å»ºé…ç½® |

---

## 7. éƒ¨ç½²åˆ° OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶

### 7.1 æ™ºèƒ½å®¶å±…åœºæ™¯åˆ†æ

**OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶ç‰¹ç‚¹**:
- ğŸ”§ **é«˜åº¦å¯å®šåˆ¶**: åŸºäº OpenClaw çš„æŠ€èƒ½ç³»ç»Ÿ
- ğŸ  **ç«¯ä¾§æ™ºèƒ½**: è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²
- ğŸ¯ **å¤šæ¨¡æ€äº¤äº’**: è¯­éŸ³ã€è§†è§‰ã€ä¼ æ„Ÿå™¨èåˆ
- âš¡ **ä½å»¶è¿Ÿè¦æ±‚**: å®æ—¶å“åº”
- ğŸ’¾ **èµ„æºå—é™**: è¾¹ç¼˜è®¾å¤‡å†…å­˜/ç®—åŠ›æœ‰é™

**ExecuTorch é€‚é…åº¦**: â­â­â­â­â­ (å®Œç¾åŒ¹é…)

### 7.2 éƒ¨ç½²æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  OpenClaw Gateway                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Fudi è¯­éŸ³åŠ©æ‰‹ (OpenClaw Agent)               â”‚  â”‚
â”‚  â”‚  - è¯­éŸ³è¯†åˆ« (Whisper)                                 â”‚  â”‚
â”‚  â”‚  - è‡ªç„¶è¯­è¨€ç†è§£ (LLM)                                  â”‚  â”‚
â”‚  â”‚  - æ„å›¾è¯†åˆ«å’ŒæŒ‡ä»¤ç”Ÿæˆ                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OpenClaw Skills (æ™ºèƒ½æŠ€èƒ½)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   è¯­éŸ³      â”‚  â”‚   è§†è§‰      â”‚  â”‚   ä¼ æ„Ÿå™¨     â”‚          â”‚
â”‚  â”‚   æŠ€èƒ½      â”‚  â”‚   æŠ€èƒ½      â”‚  â”‚   æŠ€èƒ½       â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ExecuTorch Runtime (è¾¹ç¼˜æ¨ç†å¼•æ“)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  C++ Runtime (50KB)                                   â”‚  â”‚
â”‚  â”‚  - æ¨¡å‹åŠ è½½å™¨                                          â”‚  â”‚
â”‚  â”‚  - æ‰§è¡Œå¼•æ“                                            â”‚  â”‚
â”‚  â”‚  - å†…å­˜ç®¡ç†                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Whisper.pte â”‚  â”‚  Llama.pte  â”‚  â”‚ MobileNet.  â”‚          â”‚
â”‚  â”‚ (è¯­éŸ³è¯†åˆ«)  â”‚  â”‚ (æ–‡æœ¬ç”Ÿæˆ)  â”‚  â”‚ pte (è§†è§‰)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç¡¬ä»¶åŠ é€Ÿå±‚ (Platform Backend)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   NPU       â”‚  â”‚   GPU       â”‚  â”‚   CPU       â”‚          â”‚
â”‚  â”‚  (ARM NPU)  â”‚  â”‚  (Vulkan)   â”‚  â”‚  (XNNPACK)  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 å®æ–½æ­¥éª¤

#### Step 1: ç¯å¢ƒå‡†å¤‡

**å®‰è£… ExecuTorch SDK**:

```bash
# Python ç«¯
pip install executorch

# æ£€æŸ¥å®‰è£…
python -c "import executorch; print(executorch.__version__)"
```

**å…‹éš†ä»“åº“**:

```bash
git clone https://github.com/pytorch/executorch.git
cd executorch
```

**C++ è¿è¡Œæ—¶ç¼–è¯‘** (Linux ARM/åµŒå…¥å¼):

```bash
mkdir build && cd build
cmake -DEXECUTORCH_BUILD_RUNTIME=ON \
      -DEXECUTORCH_BUILD_EXTENSION_MODULE=ON \
      -DEXECUTORCH_BUILD_XNNPACK_BACKEND=ON \
      -DEXECUTORCH_BUILD_ARM_BACKEND=ON \
      ..
make -j$(nproc)
```

#### Step 2: æ¨¡å‹å¯¼å‡º (ä»¥ Llama 3.2 ä¸ºä¾‹)

**åˆ›å»ºå¯¼å‡ºè„šæœ¬** `openclaw_models/export_llama.py`:

```python
import torch
from executorch.exir import to_edge_transform_and_lower
from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner
from executorch.extension.llm.export import export_llm
from executorch.extension.llm.tokenizer import TiktokenTokenizer

# é…ç½®
MODEL_NAME = "meta-llama/Llama-3.2-1B"
OUTPUT_PATH = "openclaw_models/llama_3.2_1b.pte"
QUANTIZE = "int8"  # int8, int4, or none

# å¯¼å‡º LLM
export_llm(
    model_name=MODEL_NAME,
    output=OUTPUT_PATH,
    quantize=QUANTIZE,
    tokenizer=TiktokenTokenizer("tiktoken.bin"),
    # é’ˆå¯¹æ™ºèƒ½å®¶å±…åœºæ™¯ä¼˜åŒ–
    max_seq_len=512,  # æ§åˆ¶æŒ‡ä»¤ä¸éœ€è¦å¤ªé•¿ä¸Šä¸‹æ–‡
    use_kv_cache=True,
)

print(f"âœ… LLM å¯¼å‡ºå®Œæˆ: {OUTPUT_PATH}")
```

**è¿è¡Œå¯¼å‡º**:

```bash
python openclaw_models/export_llama.py
```

#### Step 3: è¯­éŸ³æ¨¡å‹å¯¼å‡º (Whisper)

**åˆ›å»ºå¯¼å‡ºè„šæœ¬** `openclaw_models/export_whisper.py`:

```python
import torch
from executorch.exir import to_edge_transform_and_lower
from executorch.backends.arm.partition.arm_partitioner import ArmPartitioner

# åŠ è½½ Whisper Tiny (é€‚åˆè¾¹ç¼˜è®¾å¤‡)
from transformers import WhisperForConditionalGeneration

model = WhisperForConditionalGeneration.from_pretrained(
    "openai/whisper-tiny"
).eval()

# ç¤ºä¾‹è¾“å…¥ (éŸ³é¢‘: 16kHz, mono, 30ç§’)
example_inputs = (
    torch.randn(1, 480000),  # éŸ³é¢‘æ³¢å½¢
)

# å¯¼å‡º
exported = torch.export.export(model, example_inputs)

# ä¼˜åŒ–ä¸º ARM NPU
edge_program = to_edge_transform_and_lower(
    exported,
    partitioner=[ArmPartitioner()]
)

# ç¼–è¯‘ä¸º ExecuTorch
program = edge_program.to_executorch()

# ä¿å­˜
with open("openclaw_models/whisper_tiny.pte", "wb") as f:
    f.write(program.buffer)

print("âœ… Whisper å¯¼å‡ºå®Œæˆ: openclaw_models/whisper_tiny.pte")
```

#### Step 4: è§†è§‰æ¨¡å‹å¯¼å‡º (MobileNetV2)

**åˆ›å»ºå¯¼å‡ºè„šæœ¬** `openclaw_models/export_vision.py`:

```python
import torch
from executorch.exir import to_edge_transform_and_lower
from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner
from torchvision.models import mobilenet_v2

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = mobilenet_v2(pretrained=True).eval()

# ç¤ºä¾‹è¾“å…¥ (å›¾åƒ: 224x224, RGB)
example_inputs = (torch.randn(1, 3, 224, 224),)

# å¯¼å‡º
exported = torch.export.export(model, example_inputs)

# ä¼˜åŒ–ä¸º XNNPACK (CPU åŠ é€Ÿ)
edge_program = to_edge_transform_and_lower(
    exported,
    partitioner=[XnnpackPartitioner()]
)

# ç¼–è¯‘
program = edge_program.to_executorch()

# ä¿å­˜
with open("openclaw_models/mobilenet_v2.pte", "wb") as f:
    f.write(program.buffer)

print("âœ… MobileNetV2 å¯¼å‡ºå®Œæˆ: openclaw_models/mobilenet_v2.pte")
```

#### Step 5: åˆ›å»º OpenClaw Skill

**Skill ç›®å½•ç»“æ„**:

```
openclaw_skills/
â”œâ”€â”€ executorch_skill/
â”‚   â”œâ”€â”€ SKILL.md
â”‚   â”œâ”€â”€ runtime/
â”‚   â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”‚   â””â”€â”€ executorch.h
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ libexecutorch.so
â”‚   â”‚   â”‚   â””â”€â”€ libexecutorch_extension_module.so
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ llama_3.2_1b.pte
â”‚   â”‚       â”œâ”€â”€ whisper_tiny.pte
â”‚   â”‚       â””â”€â”€ mobilenet_v2.pte
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ export_models.py
â”‚   â”‚   â””â”€â”€ llm_wrapper.py
â”‚   â””â”€â”€ wrapper/
â”‚       â””â”€â”€ executorch_wrapper.py
```

**åˆ›å»º Skill æè¿°** `SKILL.md`:

```markdown
# ExecuTorch Edge AI Skill

## æè¿°

ä¸º OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶æä¾›ç«¯ä¾§ AI æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒï¼š
- å¤§è¯­è¨€æ¨¡å‹ (Llama 3.2)
- è¯­éŸ³è¯†åˆ« (Whisper)
- å›¾åƒè¯†åˆ« (MobileNetV2)

## ä¾èµ–

- ExecuTorch Runtime (C++)
- Python 3.10+
- PyTorch 2.3+
- å¹³å°: Linux ARM64 / x86_64

## ä½¿ç”¨æ–¹å¼

```python
from skills.executorch import LLMRunner, WhisperRunner, VisionRunner

# LLM æ¨ç†
llm = LLMRunner("models/llama_3.2_1b.pte")
response = llm.generate("æ‰“å¼€å®¢å…ç¯ï¼Œå¹¶å°†äº®åº¦è°ƒåˆ°80%")

# è¯­éŸ³è¯†åˆ«
whisper = WhisperRunner("models/whisper_tiny.pte")
text = whisper.transcribe(audio_waveform)

# å›¾åƒè¯†åˆ«
vision = VisionRunner("models/mobilenet_v2.pte")
class_name, confidence = vision.classify(image)
```

## æ€§èƒ½æŒ‡æ ‡

| æ¨¡å‹ | å»¶è¿Ÿ | å†…å­˜å ç”¨ |
|------|------|----------|
| Llama 3.2 1B (INT8) | ~50ms/token | ~1.2GB |
| Whisper Tiny (INT8) | ~100ms | ~200MB |
| MobileNetV2 (INT8) | ~15ms | ~30MB |
```

#### Step 6: åˆ›å»º C++ åŒ…è£…å™¨

**å¤´æ–‡ä»¶** `runtime/include/executorch.h`:

```cpp
#pragma once

#include <executorch/extension/module/module.h>
#include <executorch/extension/tensor/tensor.h>
#include <memory>
#include <string>
#include <vector>

namespace openclaw {
namespace executorch {

// LLM è¿è¡Œå™¨
class LLMRunner {
public:
    explicit LLMRunner(const std::string& model_path);
    ~LLMRunner();

    std::string generate(
        const std::string& prompt,
        int max_tokens = 128,
        float temperature = 0.8f
    );

    bool load_tokenizer(const std::string& tokenizer_path);

private:
    class Impl;
    std::unique_ptr<Impl> impl_;
};

// Whisper è¯­éŸ³è¯†åˆ«è¿è¡Œå™¨
class WhisperRunner {
public:
    explicit WhisperRunner(const std::string& model_path);
    ~WhisperRunner();

    std::string transcribe(
        const std::vector<float>& audio,
        float sample_rate = 16000.0f
    );

private:
    class Impl;
    std::unique_ptr<Impl> impl_;
};

// è§†è§‰è¯†åˆ«è¿è¡Œå™¨
class VisionRunner {
public:
    explicit VisionRunner(const std::string& model_path);
    ~VisionRunner();

    std::pair<std::string, float> classify(
        const std::vector<uint8_t>& image,
        int width,
        int height,
        int channels = 3
    );

private:
    class Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace executorch
} // namespace openclaw
```

#### Step 7: åˆ›å»º Python ç»‘å®š

**åŒ…è£…å™¨** `wrapper/executorch_wrapper.py`:

```python
import ctypes
import numpy as np
from pathlib import Path

class ExecutorchLLM:
    def __init__(self, model_path: str):
        # åŠ è½½ C++ åº“
        lib_path = Path(__file__).parent / "lib" / "libexecutorch_extension_module.so"
        self.lib = ctypes.CDLL(str(lib_path))

        # å®šä¹‰å‡½æ•°ç­¾å
        self.lib.create_llm_runner.restype = ctypes.c_void_p
        self.lib.llm_generate.restype = ctypes.c_char_p

        # åˆ›å»ºè¿è¡Œå™¨
        self.runner = self.lib.create_llm_runner(
            model_path.encode('utf-8')
        )

    def generate(self, prompt: str, max_tokens: int = 128) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        result = self.lib.llm_generate(
            self.runner,
            prompt.encode('utf-8'),
            max_tokens
        )
        return result.decode('utf-8')

    def __del__(self):
        if hasattr(self, 'runner') and self.runner:
            self.lib.destroy_llm_runner(self.runner)

class ExecutorchWhisper:
    def __init__(self, model_path: str):
        lib_path = Path(__file__).parent / "lib" / "libexecutorch_extension_module.so"
        self.lib = ctypes.CDLL(str(lib_path))

        self.lib.create_whisper_runner.restype = ctypes.c_void_p
        self.lib.whisper_transcribe.restype = ctypes.c_char_p

        self.runner = self.lib.create_whisper_runner(
            model_path.encode('utf-8')
        )

    def transcribe(self, audio: np.ndarray) -> str:
        """è¯­éŸ³è½¬æ–‡å­—"""
        audio_ptr = audio.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
        result = self.lib.whisper_transcribe(
            self.runner,
            audio_ptr,
            len(audio),
            16000  # sample rate
        )
        return result.decode('utf-8')

    def __del__(self):
        if hasattr(self, 'runner') and self.runner:
            self.lib.destroy_whisper_runner(self.runner)
```

#### Step 8: é›†æˆåˆ° OpenClaw Agent

**Agent ä½¿ç”¨ç¤ºä¾‹**:

```python
# openclaw_skills/executorch_skill/fudi_integration.py

from skills.executorch import ExecutorchLLM, ExecutorchWhisper

class FudiVoiceAssistant:
    def __init__(self):
        # åˆå§‹åŒ–æ¨¡å‹
        self.whisper = ExecutorchWhisper(
            "runtime/models/whisper_tiny.pte"
        )
        self.llm = ExecutorchLLM(
            "runtime/models/llama_3.2_1b.pte"
        )

    def process_voice_command(self, audio: np.ndarray) -> str:
        """å¤„ç†è¯­éŸ³æŒ‡ä»¤"""
        # 1. è¯­éŸ³è¯†åˆ«
        text = self.whisper.transcribe(audio)
        print(f"ğŸ¤ è¯†åˆ«ç»“æœ: {text}")

        # 2. æ„å›¾ç†è§£å’ŒæŒ‡ä»¤ç”Ÿæˆ
        response = self.llm.generate(
            f"ç”¨æˆ·æŒ‡ä»¤: {text}\n\nè¯·æ‰§è¡Œè¿™ä¸ªæ™ºèƒ½å®¶å±…æŒ‡ä»¤ã€‚"
        )
        print(f"ğŸ¤– AI å“åº”: {response}")

        return response

# OpenClaw Agent ä½¿ç”¨
def handle_voice_message(audio_data):
    assistant = FudiVoiceAssistant()
    result = assistant.process_voice_command(audio_data)

    # è§£æå¹¶æ‰§è¡Œæ™ºèƒ½å®¶å±…æ“ä½œ
    if "æ‰“å¼€ç¯" in result:
        # è°ƒç”¨æ™ºèƒ½å®¶å±… API
        pass
    elif "æ’­æ”¾éŸ³ä¹" in result:
        # è°ƒç”¨éŸ³ä¹æ’­æ”¾å™¨
        pass
    # ...
```

#### Step 9: éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡

**éƒ¨ç½²æ¸…å•**:

```bash
# æ„å»ºè¿è¡Œæ—¶ (ARM64)
cd executorch/build
cmake -DCMAKE_TOOLCHAIN_FILE=../cmake/toolchain-arm64.cmake \
      -DEXECUTORCH_BUILD_RUNTIME=ON \
      -DEXECUTORCH_BUILD_ARM_BACKEND=ON \
      ..
make -j$(nproc)

# æ‰“åŒ…éƒ¨ç½²æ–‡ä»¶
tar czf executorch_runtime_arm64.tar.gz \
    lib/libexecutorch.so \
    lib/libexecutorch_extension_module.so \
    include/

# å¤åˆ¶åˆ°ç›®æ ‡è®¾å¤‡
scp executorch_runtime_arm64.tar.gz \
    user@edge-device:/opt/openclaw/

# åœ¨ç›®æ ‡è®¾å¤‡ä¸Šè§£å‹
ssh user@edge-device "cd /opt/openclaw && tar xzf executorch_runtime_arm64.tar.gz"

# å¤åˆ¶æ¨¡å‹æ–‡ä»¶
scp openclaw_models/*.pte user@edge-device:/opt/openclaw/models/
```

#### Step 10: æ€§èƒ½ä¼˜åŒ–

**é‡åŒ–ä¼˜åŒ–**:

```python
# 4-bit é‡åŒ– (è¿›ä¸€æ­¥å‡å°‘å†…å­˜)
export_llm(
    model_name=MODEL_NAME,
    output=OUTPUT_PATH,
    quantize="int4",  # å†…å­˜å ç”¨å‡åŠ
    use_kv_cache=True,
    kv_cache_dtype="int8"  # KV cache é‡åŒ–
)
```

**å†…å­˜è§„åˆ’ä¼˜åŒ–**:

```python
from executorch.exir.pass import MemoryPlanningPass

# è‡ªå®šä¹‰å†…å­˜è§„åˆ’å™¨
class SmartHomeMemoryPlanner(MemoryPlanningPass):
    def __init__(self):
        super().__init__()
        self.max_memory_mb = 512  # é™åˆ¶ 512MB

    def plan(self, graph):
        # æ™ºèƒ½å†…å­˜è§„åˆ’ï¼Œé’ˆå¯¹æ™ºèƒ½å®¶å±…åœºæ™¯
        # ä¼˜å…ˆä¿è¯å®æ—¶è¯­éŸ³å’Œå›¾åƒè¯†åˆ«
        pass
```

### 7.4 OpenClaw é›†æˆä¼˜åŠ¿

| ä¼˜åŠ¿ | è¯´æ˜ |
|------|------|
| ğŸ”’ **éšç§ä¿æŠ¤** | æ‰€æœ‰ AI æ¨ç†åœ¨æœ¬åœ°å®Œæˆï¼Œæ•°æ®ä¸ä¸Šäº‘ |
| âš¡ **ä½å»¶è¿Ÿ** | ç«¯ä¾§æ¨ç†ï¼Œç½‘ç»œé›¶å»¶è¿Ÿ |
| ğŸ’¾ **èµ„æºä¼˜åŒ–** | Selective Build å‡å°‘äºŒè¿›åˆ¶å¤§å° |
| ğŸ¯ **ç²¾å‡†å®šåˆ¶** | é’ˆå¯¹æ™ºèƒ½å®¶å±…åœºæ™¯ä¼˜åŒ–æ¨¡å‹ |
| ğŸ”„ **OTA æ›´æ–°** | æ¨¡å‹å¯è¿œç¨‹æ›´æ–°ï¼Œæ— éœ€å›ºä»¶å‡çº§ |
| ğŸŒ **ç¦»çº¿å¯ç”¨** | ç½‘ç»œæ–­å¼€æ—¶ä»å¯ä½¿ç”¨ |

### 7.5 å…¸å‹åº”ç”¨åœºæ™¯

#### åœºæ™¯ 1: è¯­éŸ³æ§åˆ¶

```
ç”¨æˆ·è¯­éŸ³ â†’ Whisper (æœ¬åœ° ASR) â†’ Llama (æœ¬åœ° NLU) â†’ æ™ºèƒ½å®¶å±…è®¾å¤‡
                                              â†“
                                    "æ‰“å¼€å®¢å…ç¯ï¼Œäº®åº¦70%"
```

#### åœºæ™¯ 2: è§†è§‰ç›‘æ§

```
æ‘„åƒå¤´ â†’ MobileNetV2 (æœ¬åœ°è¯†åˆ«) â†’ Llama (æœ¬åœ°å†³ç­–) â†’ å‘Šè­¦/é€šçŸ¥
                    â†“
            æ£€æµ‹åˆ°: é™Œç”Ÿäºº (ç½®ä¿¡åº¦ 92%)
```

#### åœºæ™¯ 3: å¤šæ¨¡æ€äº¤äº’

```
è¯­éŸ³ + å›¾åƒ â†’ Multimodal Runner â†’ æ™ºèƒ½ç†è§£ä¸å“åº”
ä¾‹: "è¿™ä¸ªæ˜¯ä»€ä¹ˆæ¤ç‰©?" (åŒæ—¶æ‹æ‘„ç…§ç‰‡)
```

---

## 8. æ€»ç»“ä¸å»ºè®®

### 8.1 é¡¹ç›®æ€»ç»“

**ExecuTorch æ ¸å¿ƒä»·å€¼**:

âœ… **ç”Ÿäº§çº§æˆç†Ÿåº¦**: ç»è¿‡ Meta æ•°åäº¿ç”¨æˆ·éªŒè¯
âœ… **ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆ**: ä»å¯¼å‡ºåˆ°è¿è¡Œæ—¶çš„å®Œæ•´å·¥å…·é“¾
âœ… **å¤šç¡¬ä»¶æ”¯æŒ**: 12+ åç«¯ï¼Œè¦†ç›–ä¸»æµå¹³å°
âœ… **å¼€å‘è€…å‹å¥½**: Python ä¼˜å…ˆ APIï¼Œæ–‡æ¡£å®Œå–„
âœ… **æ€§èƒ½ä¼˜å¼‚**: 50KB è¿è¡Œæ—¶ï¼ŒAOT ä¼˜åŒ–

**é€‚ç”¨åœºæ™¯**:

- âœ… ç§»åŠ¨ç«¯ AI åº”ç”¨
- âœ… åµŒå…¥å¼ç³»ç»Ÿ (MCU)
- âœ… è¾¹ç¼˜è®¡ç®—è®¾å¤‡
- âœ… **æ™ºèƒ½å®¶å±…æ¡†æ¶** (OpenClaw Fudi)
- âœ… VR/AR è®¾å¤‡
- âœ… IoT ä¼ æ„Ÿå™¨é˜µåˆ—

### 8.2 OpenClaw æ™ºèƒ½å®¶å±…é›†æˆå»ºè®®

#### 8.2.1 æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|----------|------|
| LLM | Llama 3.2 1B (INT8) | æ€§ä»·æ¯”é«˜ï¼Œè¾¹ç¼˜è®¾å¤‡å‹å¥½ |
| ASR | Whisper Tiny (INT8) | å»¶è¿Ÿä½ï¼Œå‡†ç¡®ç‡é«˜ |
| è§†è§‰ | MobileNetV2 (INT8) | è½»é‡çº§ï¼Œè¦†ç›–å¸¸è§ç‰©ä½“ |
| åç«¯ | ARM Ethos-U / XNNPACK | è¾¹ç¼˜è®¾å¤‡å¸¸è§ç¡¬ä»¶ |

#### 8.2.2 æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å¤‡æ³¨ |
|------|--------|------|
| è¯­éŸ³è¯†åˆ«å»¶è¿Ÿ | <100ms | å®æ—¶äº¤äº’ä½“éªŒ |
| LLM é¦–å­—å»¶è¿Ÿ | <200ms | å“åº”åŠæ—¶æ€§ |
| è§†è§‰è¯†åˆ«å»¶è¿Ÿ | <50ms | ç›‘æ§åœºæ™¯è¦æ±‚ |
| å†…å­˜å ç”¨ | <2GB | è¾¹ç¼˜è®¾å¤‡é™åˆ¶ |
| åŠŸè€— | <2W | åµŒå…¥å¼è®¾å¤‡çº¦æŸ |

#### 8.2.3 å®æ–½è·¯çº¿å›¾

**Phase 1: MVP éªŒè¯ (2-4 å‘¨)**
- [ ] å¯¼å‡ºåŸºç¡€æ¨¡å‹ (Whisper, Llama)
- [ ] æ„å»ºè¿è¡Œæ—¶ç¯å¢ƒ
- [ ] å®ç° Python åŒ…è£…å™¨
- [ ] åŸºç¡€è¯­éŸ³æ§åˆ¶ demo

**Phase 2: åŠŸèƒ½å®Œå–„ (4-8 å‘¨)**
- [ ] é›†æˆè§†è§‰è¯†åˆ«
- [ ] ä¼˜åŒ–é‡åŒ–ç­–ç•¥
- [ ] å®ç°å¤šæ¨¡æ€äº¤äº’
- [ ] æ€§èƒ½è°ƒä¼˜

**Phase 3: ç”Ÿäº§éƒ¨ç½² (8-12 å‘¨)**
- [ ] è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æµ‹è¯•
- [ ] OTA æ›´æ–°æœºåˆ¶
- [ ] ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
- [ ] æ–‡æ¡£å’ŒåŸ¹è®­

#### 8.2.4 é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|----------|
| ç¡¬ä»¶æ€§èƒ½ä¸è¶³ | æ— æ³•è¾¾åˆ°å®æ—¶è¦æ±‚ | ä½¿ç”¨é‡åŒ–ã€é€‰æ‹©æ›´å°æ¨¡å‹ |
| å†…å­˜é™åˆ¶ | æ¨¡å‹æ— æ³•åŠ è½½ | Selective Buildã€å†…å­˜ä¼˜åŒ– |
| æ¨¡å‹å‡†ç¡®ç‡ä¸‹é™ | ç”¨æˆ·ä½“éªŒå·® | å¾®è°ƒæ¨¡å‹ã€ä½¿ç”¨é¢†åŸŸæ•°æ® |
| å¼€å‘å¤æ‚åº¦é«˜ | å»¶æœŸäº¤ä»˜ | å¤ç”¨å®˜æ–¹ç¤ºä¾‹ã€æ¸è¿›å¼å¼€å‘ |

### 8.3 æœ€ç»ˆå»ºè®®

**å¼ºçƒˆæ¨èåœ¨ OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶ä¸­é‡‡ç”¨ ExecuTorch**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. **æŠ€æœ¯æˆç†Ÿåº¦**: Meta ç”Ÿäº§çº§æ–¹æ¡ˆï¼Œç¨³å®šæ€§æœ‰ä¿éšœ
2. **éšç§ä¿æŠ¤**: ç«¯ä¾§æ¨ç†ï¼Œæ•°æ®ä¸ä¸Šäº‘ï¼Œç¬¦åˆæ™ºèƒ½å®¶å±…éšç§è¦æ±‚
3. **æ€§èƒ½ä¼˜å¼‚**: AOT ç¼–è¯‘ + ç¡¬ä»¶åŠ é€Ÿï¼Œæ»¡è¶³å®æ—¶æ€§è¦æ±‚
4. **ç”Ÿæ€å®Œå–„**: å®˜æ–¹ç¤ºä¾‹ä¸°å¯Œï¼Œæ–‡æ¡£è¯¦ç»†ï¼Œç¤¾åŒºæ´»è·ƒ
5. **æœªæ¥å¯æ‰©å±•**: æ”¯æŒæ›´å¤šç¡¬ä»¶åç«¯å’Œæ¨¡å‹ç±»å‹

**å…³é”®æˆåŠŸå› ç´ **:
- âœ… æ­£ç¡®çš„æ¨¡å‹é€‰æ‹©å’Œé‡åŒ–ç­–ç•¥
- âœ… é’ˆå¯¹æ™ºèƒ½å®¶å±…åœºæ™¯çš„ä¼˜åŒ–
- âœ… å®Œå–„çš„æµ‹è¯•å’Œç›‘æ§ä½“ç³»
- âœ… æ¸è¿›å¼å¼€å‘ï¼Œå¿«é€Ÿè¿­ä»£

---

## é™„å½•

### A. å‚è€ƒèµ„æº

**å®˜æ–¹æ–‡æ¡£**:
- [ExecuTorch æ–‡æ¡£é¦–é¡µ](https://docs.pytorch.org/executorch/main/index.html)
- [æ¶æ„æŒ‡å—](https://docs.pytorch.org/executorch/main/getting-started-architecture.html)
- [å¿«é€Ÿå¼€å§‹](https://docs.pytorch.org/executorch/main/quick-start-section.html)

**ä»£ç ä»“åº“**:
- [GitHub ä»“åº“](https://github.com/pytorch/executorch)
- [ç¤ºä¾‹é¡¹ç›®](https://github.com/meta-pytorch/executorch-examples)
- [HuggingFace Optimum-ExecuTorch](https://github.com/huggingface/optimum-executorch)

**ç¤¾åŒº**:
- [Discord](https://discord.gg/Dh43CKSAdc)
- [GitHub Discussions](https://github.com/pytorch/executorch/discussions)

### B. ç›¸å…³æŠ€æœ¯

| æŠ€æœ¯ | è¯´æ˜ | ä¸ ExecuTorch å…³ç³» |
|------|------|-------------------|
| ONNX Runtime | è·¨å¹³å°æ¨ç†æ¡†æ¶ | ç«å“ï¼Œä½†éœ€æ ¼å¼è½¬æ¢ |
| TFLite | TensorFlow è½»é‡çº§æ¨ç† | ç«å“ï¼Œå±€é™äº TensorFlow |
| TensorRT | NVIDIA GPU åŠ é€Ÿ | äº’è¡¥ï¼Œå¯ç»“åˆä½¿ç”¨ |
| XNNPACK | CPU æ¨ç†åŠ é€Ÿåº“ | ExecuTorch åç«¯ä¹‹ä¸€ |

### C. æœ¯è¯­è¡¨

| æœ¯è¯­ | è¯´æ˜ |
|------|------|
| AOT (Ahead-of-Time) | æå‰ç¼–è¯‘ï¼Œåœ¨éƒ¨ç½²å‰å®Œæˆæ‰€æœ‰ç¼–è¯‘å·¥ä½œ |
| EXIR | Export Intermediate Representationï¼ŒExecuTorch çš„ä¸­é—´è¡¨ç¤º |
| ATen | PyTorch çš„å¼ é‡è¿ç®—åº“ |
| Flatbuffer | é«˜æ•ˆçš„äºŒè¿›åˆ¶åºåˆ—åŒ–æ ¼å¼ |
| KV Cache | Key-Value Cacheï¼ŒLLM æ¨ç†ä¼˜åŒ–æŠ€æœ¯ |
| Partitioner | åˆ†åŒºå™¨ï¼Œå†³å®šå“ªäº›ç®—å­å§”æ‰˜åˆ°åç«¯ |
| Delegate | å§”æ‰˜ï¼Œå°†è®¡ç®—å­å›¾äº¤ç»™ä¸“ç”¨ç¡¬ä»¶æ‰§è¡Œ |
| Selective Build | é€‰æ‹©æ€§æ„å»ºï¼Œä»…é“¾æ¥éœ€è¦çš„ç®—å­ |

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-02-22
**åˆ†æå·¥å…·**: Joy (OpenClaw AI Assistant)
**ç‰ˆæœ¬**: v1.0

---

*æ­¤æŠ¥å‘Šä¸ºå¼€æºé¡¹ç›®åˆ†æï¼Œç”¨äºæŠ€æœ¯è¯„ä¼°å’Œå†³ç­–å‚è€ƒã€‚*
